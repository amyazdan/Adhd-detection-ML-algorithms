{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self):\n",
    "        \n",
    "        # whole dataset\n",
    "        df = pd.read_csv('dataset_2.csv')\n",
    "        self.y = df['K2Q31A']\n",
    "        self.X = df.drop(columns='K2Q31A')\n",
    "\n",
    "        # chi square\n",
    "        self.chi = pd.read_csv('chi.csv')\n",
    "        self.chi = self.chi.loc[self.chi['Dr Sheikhy'] == 'Y']['feature name']\n",
    "        \n",
    "        # fisher's score\n",
    "        self.fisher = pd.read_csv('fisher.csv')\n",
    "        self.fisher = self.fisher.loc[self.fisher['Dr Sheikhy'] == 'Y']['Feature Name']\n",
    "\n",
    "        # information gain\n",
    "        self.inf = pd.read_csv('inf-gain.csv')\n",
    "        self.inf = self.inf.loc[self.inf['Dr Sheikhy'] == 'Y']['Feature Name']\n",
    "\n",
    "        # corelation\n",
    "        self.cor = pd.read_csv('cor.csv')\n",
    "        self.cor = self.cor.iloc[:,[0, 14]].where(self.cor.iloc[:,14] == 'Y').dropna().iloc[:, 0]\n",
    "\n",
    "    def return_dataset(self)->pd.DataFrame:\n",
    "        return self.X, self.y\n",
    "\n",
    "    def return_chi(self)->pd.Series:\n",
    "        return self.chi\n",
    "    \n",
    "    def return_fisher(self)->pd.Series:\n",
    "        return self.fisher\n",
    "    \n",
    "    def return_inf(self)->pd.Series:\n",
    "        return self.inf\n",
    "    \n",
    "    def return_cor(self)->pd.Series:\n",
    "        return self.cor\n",
    "    \n",
    "    def return_intersection_chi_fisher(self) -> list:\n",
    "        return list(set(self.chi.tolist()) & set(self.fisher.tolist()))\n",
    "\n",
    "    def return_intersection_chi_inf(self) -> list:\n",
    "        return list(set(self.chi.tolist()) & set(self.inf.tolist()))\n",
    "\n",
    "    def return_intersection_chi_cor(self) -> list:\n",
    "        return list(set(self.chi.tolist()) & set(self.cor.tolist()))\n",
    "    \n",
    "    def return_intersection_fisher_inf(self) -> list:\n",
    "        return list(set(self.fisher.tolist()) & set(self.inf.tolist()))\n",
    "\n",
    "    def return_intersection_fisher_cor(self) -> list:\n",
    "        return list(set(self.fisher.tolist()) & set(self.cor.tolist()))\n",
    "\n",
    "    def return_intersection_inf_cor(self) -> list:\n",
    "        return list(set(self.inf.tolist()) & set(self.cor.tolist()))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit_xgboost(self):\n",
    "        pass\n",
    "\n",
    "    def fit_adaboost(self):\n",
    "        pass\n",
    "\n",
    "    def fit_gradient_boost(self):\n",
    "        pass\n",
    "\n",
    "    def fit_random_forest(self):\n",
    "        pass\n",
    "    \n",
    "    def fit_svm(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K4Q23',\n",
       " 'K2Q33A',\n",
       " 'MEMORYCOND',\n",
       " 'K4Q22_R',\n",
       " 'K2Q60A',\n",
       " 'K2Q34A',\n",
       " 'TOTFEMALE',\n",
       " 'ACE3',\n",
       " 'K2Q36A',\n",
       " 'K2Q30A',\n",
       " 'K2Q37A',\n",
       " 'SC_K2Q22',\n",
       " 'K2Q35A',\n",
       " 'ACE8',\n",
       " 'K7Q70_R',\n",
       " 'ACE11',\n",
       " 'K2Q40A']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset()\n",
    "X, y = dataset.return_dataset()\n",
    "X.shape, y.shape\n",
    "b = dataset.return_cor()\n",
    "b\n",
    "a = dataset.return_intersection_fisher_cor()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8532, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# selected_cols_chi_fisher = perfect.loc[:, df.columns.isin(chi_fisher)]\n",
    "# selected_cols_chi_fisher.shape\n",
    "\n",
    "# selected_cols_inf_fisher = perfect.loc[:, df.columns.isin(inf_fisher)]\n",
    "# selected_cols_inf_fisher.shape\n",
    "\n",
    "# selected_cols_inf_chi = perfect.loc[:, df.columns.isin(inf_chi)]\n",
    "# selected_cols_inf_chi.shape\n",
    "\n",
    "# selected_cols_chi_fisher_inf = perfect.loc[:, df.columns.isin(chi_fisher_inf)]\n",
    "# selected_cols_chi_fisher_inf.shape\n",
    "\n",
    "# selected_cols_chi_fisher_inf_intersect = perfect.loc[:, df.columns.isin(chi_fisher_inf_intersect)]\n",
    "# selected_cols_chi_fisher_inf.shape\n",
    "\n",
    "# selected_cols_all = perfect.loc[:, df.columns.isin(all)]\n",
    "# selected_cols_chi_fisher_inf.shape\n",
    "\n",
    "# selected_cols_inf_chi_inter = perfect.loc[:, df.columns.isin(inf_chi_intersect)]\n",
    "# selected_cols_chi_fisher_inf.shape\n",
    "\n",
    "# target_perfect.shape\n",
    "\n",
    "# selected_cols_inf_chi_inter.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### under sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27449,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# selected_cols_inf_chi = df.loc[:, df.columns.isin(inf_chi_intersect)]\n",
    "# selected_cols_inf_chi.shape\n",
    "# y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "no_iter = 150\n",
    "xgboost_score_no_iter = list()\n",
    "\n",
    "for i in range(no_iter):\n",
    "\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "    X_shuffled, y_shuffled = undersample.fit_resample(selected_cols_inf_chi, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    \n",
    "    y_train = -(y_train - 2)\n",
    "    y_test = -(y_test - 2)\n",
    "\n",
    "    classifiers = [\n",
    "        XGBClassifier(max_depth=5,\n",
    "            learning_rate=0.01,\n",
    "            n_estimators=100,\n",
    "            objective='binary:logistic',\n",
    "            random_state=42)\n",
    "    ]\n",
    "\n",
    "    # scores = []\n",
    "    # times = []\n",
    "    # iterate over the classifiers and fit them to the training data\n",
    "    for clf in classifiers:\n",
    "        # start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        end_time = time.time()\n",
    "        # time0 = end_time - start_time\n",
    "        # times.append(time0)\n",
    "        \n",
    "        # print(type(clf).__name__, \"Accuracy:\", accuracy, 'time: ', time0)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        xgboost_score_no_iter.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8635891427455576,\n",
       " 0.8799062683069713,\n",
       " 0.849443468072642,\n",
       " 0.005739626035014794]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_score_no_iter_np = np.array(xgboost_score_no_iter)\n",
    "xgboost_score_no_iter_mean = xgboost_score_no_iter_np.mean()\n",
    "\n",
    "xgboost_result = [xgboost_score_no_iter_np.mean(), xgboost_score_no_iter_np.max(), \\\n",
    "                  xgboost_score_no_iter_np.min(), xgboost_score_no_iter_np.std()]\n",
    "xgboost_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.,  0., 12., 20., 30., 33., 24., 18.,  5.,  4.]),\n",
       " array([0.84475688, 0.84797891, 0.85120094, 0.85442296, 0.85764499,\n",
       "        0.86086702, 0.86408905, 0.86731107, 0.8705331 , 0.87375513,\n",
       "        0.87697715]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(xgboost_score_no_iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "no_iter = 150\n",
    "adaBoost_score_no_iter = list()\n",
    "\n",
    "for i in range(no_iter):\n",
    "    # idx = np.random.permutation(len(perfect))\n",
    "    # # X_shuffled, y_shuffled = perfect.iloc[idx], target_perfect.iloc[idx]\n",
    "    # X_shuffled, y_shuffled = perfect.loc[:, df.columns.isin(selected_cols_inf_chi_inter)]\\\n",
    "    # .iloc[idx], target_perfect.iloc[idx]\n",
    "    X_shuffled, y_shuffled = undersample.fit_resample(selected_cols_inf_chi, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "    y_train = -(y_train - 2)\n",
    "    y_test = -(y_test - 2)\n",
    "\n",
    "    classifiers = [\n",
    "        # RandomForestClassifier(),\n",
    "        # SVC(),\n",
    "        AdaBoostClassifier()\n",
    "        # GradientBoostingClassifier(),\n",
    "    #     XGBClassifier(max_depth=5,\n",
    "    #         learning_rate=0.1,\n",
    "    #         n_estimators=100,\n",
    "    #         objective='binary:logistic',\n",
    "    #         random_state=42)\n",
    "    ]\n",
    "\n",
    "    # scores = []\n",
    "    # times = []\n",
    "    # iterate over the classifiers and fit them to the training data\n",
    "    for clf in classifiers:\n",
    "        # start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        end_time = time.time()\n",
    "        # time0 = end_time - start_time\n",
    "        # times.append(time0)\n",
    "        \n",
    "        # print(type(clf).__name__, \"Accuracy:\", accuracy, 'time: ', time0)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        adaBoost_score_no_iter.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8565241163835189, 0.872290568248389, 0.836555360281195, 0.00557812550034245]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaBoost_score_no_iter_np = np.array(adaBoost_score_no_iter)\n",
    "adaBoost_score_no_iter_mean = adaBoost_score_no_iter_np.mean()\n",
    "\n",
    "adaBoost_result = [adaBoost_score_no_iter_np.mean(), adaBoost_score_no_iter_np.max(), \\\n",
    "                  adaBoost_score_no_iter_np.min(), adaBoost_score_no_iter_np.std()]\n",
    "adaBoost_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "no_iter = 150\n",
    "GradientBoostingClassifier_score_no_iter = list()\n",
    "\n",
    "for i in range(no_iter):\n",
    "    # idx = np.random.permutation(len(perfect))\n",
    "    # # X_shuffled, y_shuffled = perfect.iloc[idx], target_perfect.iloc[idx]\n",
    "    # X_shuffled, y_shuffled = perfect.loc[:, df.columns.isin(selected_cols_inf_chi_inter)]\\\n",
    "    # .iloc[idx], target_perfect.iloc[idx]\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    X_shuffled, y_shuffled = undersample.fit_resample(selected_cols_inf_chi, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "    y_train = -(y_train - 2)\n",
    "    y_test = -(y_test - 2)\n",
    "\n",
    "    classifiers = [\n",
    "        # RandomForestClassifier(),\n",
    "        # SVC(),\n",
    "        # AdaBoostClassifier()\n",
    "        GradientBoostingClassifier()\n",
    "    #     XGBClassifier(max_depth=5,\n",
    "    #         learning_rate=0.1,\n",
    "    #         n_estimators=100,\n",
    "    #         objective='binary:logistic',\n",
    "    #         random_state=42)\n",
    "    ]\n",
    "\n",
    "    # scores = []\n",
    "    # times = []\n",
    "    # iterate over the classifiers and fit them to the training data\n",
    "    for clf in classifiers:\n",
    "        # start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        end_time = time.time()\n",
    "        # time0 = end_time - start_time\n",
    "        # times.append(time0)\n",
    "        \n",
    "        # print(type(clf).__name__, \"Accuracy:\", accuracy, 'time: ', time0)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        GradientBoostingClassifier_score_no_iter.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8636360085920717,\n",
       " 0.8763913298183948,\n",
       " 0.8453427065026362,\n",
       " 0.005744311882834405]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GradientBoostingClassifier_score_no_iter_np = np.array(GradientBoostingClassifier_score_no_iter)\n",
    "GradientBoostingClassifier_score_no_iter_mean = GradientBoostingClassifier_score_no_iter_np.mean()\n",
    "\n",
    "GradientBoostingClassifier_result = [GradientBoostingClassifier_score_no_iter_np.mean(), GradientBoostingClassifier_score_no_iter_np.max(), \\\n",
    "                  GradientBoostingClassifier_score_no_iter_np.min(), GradientBoostingClassifier_score_no_iter_np.std()]\n",
    "GradientBoostingClassifier_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "no_iter = 150\n",
    "SVM_score_no_iter = list()\n",
    "\n",
    "for i in range(no_iter):\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "    # idx = np.random.permutation(len(perfect))\n",
    "    # # X_shuffled, y_shuffled = perfect.iloc[idx], target_perfect.iloc[idx]\n",
    "    # X_shuffled, y_shuffled = perfect.loc[:, df.columns.isin(selected_cols_inf_chi_inter)]\\\n",
    "    # .iloc[idx], target_perfect.iloc[idx]\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "    X_shuffled, y_shuffled = undersample.fit_resample(selected_cols_inf_chi, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    y_train = -(y_train - 2)\n",
    "    y_test = -(y_test - 2)\n",
    "\n",
    "    classifiers = [\n",
    "        # RandomForestClassifier()\n",
    "        SVC()\n",
    "        # AdaBoostClassifier()\n",
    "        # GradientBoostingClassifier()\n",
    "    #     XGBClassifier(max_depth=5,\n",
    "    #         learning_rate=0.1,\n",
    "    #         n_estimators=100,\n",
    "    #         objective='binary:logistic',\n",
    "    #         random_state=42)\n",
    "    ]\n",
    "\n",
    "    # scores = []\n",
    "    # times = []\n",
    "    # iterate over the classifiers and fit them to the training data\n",
    "    for clf in classifiers:\n",
    "        # start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        end_time = time.time()\n",
    "        # time0 = end_time - start_time\n",
    "        # times.append(time0)\n",
    "        \n",
    "        # print(type(clf).__name__, \"Accuracy:\", accuracy, 'time: ', time0)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        SVM_score_no_iter.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8492520991993752,\n",
       " 0.8611599297012302,\n",
       " 0.8330404217926186,\n",
       " 0.005687211454896837]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_score_no_iter_np = np.array(SVM_score_no_iter)\n",
    "SVM_score_no_iter_mean = SVM_score_no_iter_np.mean()\n",
    "\n",
    "SVM_result = [SVM_score_no_iter_np.mean(), SVM_score_no_iter_np.max(), \\\n",
    "                  SVM_score_no_iter_np.min(), SVM_score_no_iter_np.std()]\n",
    "SVM_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "no_iter = 150\n",
    "RandomForestClassifier_score_no_iter = list()\n",
    "\n",
    "for i in range(no_iter):\n",
    "    # idx = np.random.RandomState(seed=42).permutation(len(perfect))\n",
    "    # # X_shuffled, y_shuffled = perfect.iloc[idx], target_perfect.iloc[idx]\n",
    "    # X_shuffled, y_shuffled = perfect.loc[:, df.columns.isin(selected_cols_inf_chi_inter)]\\\n",
    "    # .iloc[idx], target_perfect.iloc[idx]\n",
    "    X_shuffled, y_shuffled = undersample.fit_resample(selected_cols_inf_chi, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_shuffled, y_shuffled, test_size=0.2, random_state=0)\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "    y_train = -(y_train - 2)\n",
    "    y_test = -(y_test - 2)\n",
    "\n",
    "    classifiers = [\n",
    "        RandomForestClassifier()\n",
    "        # SVC()\n",
    "        # AdaBoostClassifier()\n",
    "        # GradientBoostingClassifier()\n",
    "    #     XGBClassifier(max_depth=5,\n",
    "    #         learning_rate=0.1,\n",
    "    #         n_estimators=100,\n",
    "    #         objective='binary:logistic',\n",
    "    #         random_state=42)\n",
    "    ]\n",
    "\n",
    "    # scores = []\n",
    "    # times = []\n",
    "    # iterate over the classifiers and fit them to the training data\n",
    "    for clf in classifiers:\n",
    "        # start_time = time.time()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        end_time = time.time()\n",
    "        # time0 = end_time - start_time\n",
    "        # times.append(time0)\n",
    "        \n",
    "        # print(type(clf).__name__, \"Accuracy:\", accuracy, 'time: ', time0)\n",
    "        # score = accuracy_score(y_test, y_pred)\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        RandomForestClassifier_score_no_iter.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8528412419449326,\n",
       " 0.8640890451083773,\n",
       " 0.8394844756883422,\n",
       " 0.005496756464318646]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier_score_no_iter_np = np.array(RandomForestClassifier_score_no_iter)\n",
    "RandomForestClassifier_score_no_iter_mean = RandomForestClassifier_score_no_iter_np.mean()\n",
    "\n",
    "RandomForestClassifier_result = [RandomForestClassifier_score_no_iter_np.mean(), RandomForestClassifier_score_no_iter_np.max(), \\\n",
    "                  RandomForestClassifier_score_no_iter_np.min(), RandomForestClassifier_score_no_iter_np.std()]\n",
    "RandomForestClassifier_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
