{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3qaCwQE1F6tm"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from scipy import stats as st\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSgrK4B4J5Vd",
        "outputId": "98ef085c-d9b6-489b-cee2-61f2cd221967"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MrMHrawKF6tv"
      },
      "outputs": [],
      "source": [
        "class Dataset():\n",
        "    def __init__(self):\n",
        "\n",
        "        # whole dataset\n",
        "        df = pd.read_csv('/content/drive/MyDrive/ADHD/file/na.csv')\n",
        "        self.y = df['K2Q31A']\n",
        "        self.X = df.drop(columns='K2Q31A')\n",
        "\n",
        "        # chi square\n",
        "        self.chi = pd.read_csv('/content/drive/MyDrive/adhd_tune/Adhd-detection-ML-algorithms/chi.csv')\n",
        "        self.chi = self.chi.loc[self.chi['Dr Sheikhy'] == 'Y']['feature name']\n",
        "\n",
        "        # fisher's score\n",
        "        self.fisher = pd.read_csv('/content/drive/MyDrive/adhd_tune/Adhd-detection-ML-algorithms/fisher.csv')\n",
        "        self.fisher = self.fisher.loc[self.fisher['Dr Sheikhy'] == 'Y']['Feature Name']\n",
        "\n",
        "        # information gain\n",
        "        self.inf = pd.read_csv('/content/drive/MyDrive/adhd_tune/Adhd-detection-ML-algorithms/inf-gain.csv')\n",
        "        self.inf = self.inf.loc[self.inf['Dr Sheikhy'] == 'Y']['Feature Name']\n",
        "\n",
        "        # corelation\n",
        "        self.cor = pd.read_csv('/content/drive/MyDrive/adhd_tune/Adhd-detection-ML-algorithms/cor.csv')\n",
        "        self.cor = self.cor.iloc[:,[0, 14]].where(self.cor.iloc[:,14] == 'Y').dropna().iloc[:, 0]\n",
        "\n",
        "    def return_dataset(self) -> pd.DataFrame:\n",
        "        return self.X, self.y\n",
        "\n",
        "    def return_chi(self) -> pd.Series:\n",
        "        return self.chi\n",
        "\n",
        "    def return_fisher(self) -> pd.Series:\n",
        "        return self.fisher\n",
        "\n",
        "    def return_inf(self) -> pd.Series:\n",
        "        return self.inf\n",
        "\n",
        "    def return_cor(self) -> pd.Series:\n",
        "        return self.cor\n",
        "\n",
        "    # intersections of 2 sets\n",
        "    def return_intersection_chi_fisher(self) -> list:\n",
        "        return list(set(self.chi.tolist()) & set(self.fisher.tolist()))\n",
        "\n",
        "    def return_intersection_chi_inf(self) -> list:\n",
        "        return list(set(self.chi.tolist()) & set(self.inf.tolist()))\n",
        "\n",
        "    def return_intersection_chi_cor(self) -> list:\n",
        "        return list(set(self.chi.tolist()) & set(self.cor.tolist()))\n",
        "\n",
        "    def return_intersection_fisher_inf(self) -> list:\n",
        "        return list(set(self.fisher.tolist()) & set(self.inf.tolist()))\n",
        "\n",
        "    def return_intersection_fisher_cor(self) -> list:\n",
        "        return list(set(self.fisher.tolist()) & set(self.cor.tolist()))\n",
        "\n",
        "    def return_intersection_inf_cor(self) -> list:\n",
        "        return list(set(self.inf.tolist()) & set(self.cor.tolist()))\n",
        "\n",
        "    # intersections of 3 sets\n",
        "    def return_intersection_chi_fisher_inf(self) -> list:\n",
        "        return list(set(self.chi.tolist()) & set(self.fisher.tolist()) & set(self.inf.tolist()))\n",
        "\n",
        "    def return_intersection_chi_fisher_cor(self) -> list:\n",
        "        return list(set(self.chi.tolist()) & set(self.fisher.tolist()) & set(self.cor.tolist()))\n",
        "\n",
        "    def return_intersection_chi_inf_cor(self) -> list:\n",
        "        return list(set(self.chi.tolist()) & set(self.inf.tolist()) & set(self.cor.tolist()))\n",
        "\n",
        "    def return_intersection_fisher_inf_cor(self) -> list:\n",
        "        return list(set(self.fisher.tolist()) & set(self.inf.tolist()) & set(self.cor.tolist()))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Kjzt-AeKFGnH"
      },
      "outputs": [],
      "source": [
        "class EnsembleModel():\n",
        "  def __init__(self,models: list ):\n",
        "    '''\n",
        "    This class gives a list of odd number classifier and predict\n",
        "    based on the frequent prediction.\n",
        "\n",
        "    '''\n",
        "    self.models=models\n",
        "    self.fitted_models=[]\n",
        "\n",
        "\n",
        "\n",
        "  def fit(self,X_train: pd.DataFrame ,y_train: pd.DataFrame):\n",
        "    '''\n",
        "    Fitting functinon\n",
        "    This function fits the models that are input of an object\n",
        "    '''\n",
        "    for model in self.models:\n",
        "      self.fitted_models.append(model.fit(X_train,y_train))\n",
        "\n",
        "\n",
        "  def predict(self,X_test,show_result=False):\n",
        "    '''\n",
        "    This function makes prediction based on frequent predicted values\n",
        "\n",
        "    '''\n",
        "    pred=[]\n",
        "    for model in self.fitted_models:\n",
        "      pred.append(model.predict(X_test))\n",
        "\n",
        "    pred_array=np.array(pred)\n",
        "    y_pred=st.mode(pred_array,axis=0,keepdims=True)[0]\n",
        "\n",
        "\n",
        "\n",
        "    if not show_result:\n",
        "      return y_pred.reshape(-1,)\n",
        "\n",
        "\n",
        "\n",
        "    if show_result:\n",
        "      return  y_pred.reshape(-1,) , pred.reshape(-1,len(self.models))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RooQrahBF6t7"
      },
      "outputs": [],
      "source": [
        "class Model():\n",
        "    def __init__(self, no_iters: int, selection: list, x: pd.DataFrame, y: pd.DataFrame, filename: str):\n",
        "\n",
        "        self.no_iters = no_iters\n",
        "\n",
        "        self.x = x.loc[:, x.columns.isin(selection)]\n",
        "        self.y = y\n",
        "\n",
        "\n",
        "        self.filename = str(self._create_filename(filename) + '.text').replace(\"'\", \"\")\n",
        "\n",
        "        # [name, acc, f1_score, recall, precision, time]\n",
        "        # self.xgboost_result = []\n",
        "        # self.adaboost_result = []\n",
        "        # self.gradient_boost_result = []\n",
        "        # self.random_forest_result = []\n",
        "        # self.svm_result = []\n",
        "        # self.ensemble_result=[]\n",
        "\n",
        "        # classifiers\n",
        "        self.xgboost_classifier = XGBClassifier(max_depth=5,\n",
        "        learning_rate=0.005,\n",
        "        n_estimators=100,\n",
        "        objective='binary:logistic',\n",
        "        random_state=42)\n",
        "\n",
        "        self.adaboost_classifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.05,\n",
        "        algorithm='SAMME.R',\n",
        "        random_state=42,\n",
        "        base_estimator='deprecated')\n",
        "\n",
        "        self.svm_classifier = SVC()\n",
        "\n",
        "        self.random_forest_classifier = RandomForestClassifier()\n",
        "\n",
        "        self.gradient_boost_classifier = GradientBoostingClassifier()\n",
        "\n",
        "        self.decision_tree_classifier= DecisionTreeClassifier()\n",
        "\n",
        "        self.logistic_regression=LogisticRegression(random_state=0,max_iter=300)\n",
        "        #ensemble learning classifier uses the object classifer as input\n",
        "        self.ensemble_classifier=EnsembleModel([self.xgboost_classifier,self.gradient_boost_classifier,self.adaboost_classifier,self.svm_classifier,self.logistic_regression])\n",
        "\n",
        "        # undersampling\n",
        "        self.undersample = RandomUnderSampler(sampling_strategy='majority',random_state=9)\n",
        "        self.X_us , self.y_us= self.undersample.fit_resample(self.x, self.y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _append_items(self, target: list, name, acc, f1_score, recall, precision, time, no_iters):\n",
        "        target.append(name)\n",
        "        target.append(acc)\n",
        "        target.append(f1_score)\n",
        "        target.append(recall)\n",
        "        target.append(precision)\n",
        "        target.append(time)\n",
        "        target.append(no_iters)\n",
        "        return target\n",
        "\n",
        "    def _train(self, classifier, random_state=0):\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(self.X_us, self.y_us, test_size=0.2)\n",
        "\n",
        "\n",
        "        #imputing missing values\n",
        "        imputer = SimpleImputer(strategy='median')\n",
        "        imputer.fit(X_train)\n",
        "\n",
        "        X_train = imputer.transform(X_train)\n",
        "        X_test = imputer.transform(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        y_train = -(y_train - 2)\n",
        "        y_test = -(y_test - 2)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        time0 = end_time - start_time\n",
        "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "\n",
        "        return accuracy, f1, recall, precision, time0\n",
        "    # [name, acc, f1_score, recall, precision, time]\n",
        "\n",
        "\n",
        "    def display_result(self, result, print_result=True):\n",
        "        filename ='/content/drive/MyDrive/elec/filesss/'+str(self.filename)\n",
        "        with open(filename, 'a') as file:\n",
        "            result_string = (f'algorithm name: {result[0]}\\n'\n",
        "                f'number of iterations: {str(self.no_iters)}\\n'\n",
        "                f'average accuracy: {(result[1]).mean():.4f}' + '\\n'\n",
        "                f'max accuracy: {(result[1]).max():.4f}' + '\\n'\n",
        "                f'std accuracy: {(result[1]).std():.4f}' + '\\n'\n",
        "                f'average f1 score: {(result[2]).mean():.4f}' + '\\n'\n",
        "                f'max f1 score: {(result[2]).max():.4f}' + '\\n'\n",
        "                f'std f1 score: {(result[2]).std():.4f}' + '\\n'\n",
        "                f'average recall: {(result[3]).mean():.4f}' + '\\n'\n",
        "                f'max recall: {(result[3]).max():.4f}' + '\\n'\n",
        "                f'std recall: {(result[3]).std():.4f}' + '\\n'\n",
        "                f'average precision: {(result[4]).mean():.4f}' + '\\n'\n",
        "                f'max precision: {(result[4]).max():.4f}' + '\\n'\n",
        "                f'std precision: {(result[4]).std():.4f}' + '\\n'\n",
        "                f'average time: {result[5].mean():.4f}' + '\\n\\n\\n')\n",
        "            if print_result:\n",
        "                print(result_string)\n",
        "            file.write(result_string)\n",
        "        file.close()\n",
        "\n",
        "\n",
        "    def fit_algorithm(self, classifier):\n",
        "\n",
        "        scores = []\n",
        "        times = []\n",
        "        f1_scores = []\n",
        "        recall_scores = []\n",
        "        precision_scores = []\n",
        "\n",
        "        for _ in range(self.no_iters):\n",
        "\n",
        "            accuracy, f1, recall, precision, time0 = self._train(classifier)\n",
        "\n",
        "            scores.append(accuracy)\n",
        "            f1_scores.append(f1)\n",
        "            recall_scores.append(recall)\n",
        "            precision_scores.append(precision)\n",
        "            times.append(time0)\n",
        "\n",
        "        target = []\n",
        "\n",
        "\n",
        "        name = classifier\n",
        "        if  name == self.xgboost_classifier:\n",
        "            name = XGBClassifier.__name__\n",
        "        if name==self.ensemble_classifier:\n",
        "            name = EnsembleModel.__name__\n",
        "\n",
        "        target = self._append_items(target=target, name=name, acc=np.array(scores),\n",
        "                            f1_score=np.array(f1_scores), recall=np.array(recall_scores),\n",
        "                            precision=np.array(precision_scores), time=np.array(times), no_iters=self.no_iters)\n",
        "        self.display_result(target)\n",
        "\n",
        "    def _create_filename(self, filename):\n",
        "        index = filename.find(\"return_\")\n",
        "        if index == -1:\n",
        "            return None\n",
        "        else:\n",
        "            return filename[index + len(\"return_\"):]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cqXnMlS_F6uB"
      },
      "outputs": [],
      "source": [
        "no_iterarion =30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X0jcytxNFGnb",
        "outputId": "7b7b1b1f-9212-469b-d372-a565b190a88e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ],
      "source": [
        "def data():\n",
        "    print(5)\n",
        "data.__name__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "38irSnZlF6uF"
      },
      "outputs": [],
      "source": [
        "dataset  = Dataset()\n",
        "X, y = dataset.return_dataset()\n",
        "\n",
        "models=[Model(no_iters=no_iterarion, selection=dataset.return_intersection_chi_inf(), x=X, y=y,filename=dataset.return_intersection_chi_inf.__name__),\n",
        "       Model(no_iters=no_iterarion,selection=dataset.return_intersection_chi_fisher_inf(),x=X, y=y, filename=dataset.return_intersection_chi_fisher_inf.__name__),\n",
        "      Model(no_iters=no_iterarion,selection=dataset.return_intersection_chi_fisher(),x=X, y=y,filename=dataset.return_intersection_chi_fisher.__name__),\n",
        "      Model(no_iters=no_iterarion,selection=dataset.return_intersection_chi_inf(),x=X, y=y, filename=dataset.return_intersection_chi_inf.__name__),\n",
        "      Model(no_iters=no_iterarion,selection=dataset.return_intersection_fisher_inf(),x=X, y=y,filename=dataset.return_intersection_fisher_inf.__name__),\n",
        "      Model(no_iters=no_iterarion,selection=dataset.return_intersection_chi_cor(),x=X, y=y, filename=dataset.return_intersection_chi_cor.__name__),\n",
        "      Model(no_iters=no_iterarion,selection=dataset.return_intersection_fisher_cor(),x=X, y=y, filename=dataset.return_intersection_fisher_cor.__name__),\n",
        "      Model(no_iters=no_iterarion,selection=dataset.return_intersection_inf_cor(),x=X, y=y,filename=str(dataset.return_intersection_inf_cor.__name__))\n",
        "]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "UwKEks9OF6uL"
      },
      "outputs": [],
      "source": [
        "# classifiers =   [\n",
        "#                 model.xgboost_classifier,\n",
        "#                 model.adaboost_classifier,\n",
        "#                 model.gradient_boost_classifier,\n",
        "#                 model.random_forest_classifier,\n",
        "#                 model.svm_classifier,\n",
        "#                 model.ensemble_classifier\n",
        "#                 ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "  classifiers =   [\n",
        "                model.xgboost_classifier,\n",
        "                model.adaboost_classifier,\n",
        "                model.gradient_boost_classifier,\n",
        "                model.random_forest_classifier,\n",
        "                model.svm_classifier\n",
        "                # model.ensemble_classifier\n",
        "                ]\n",
        "  for classifier in classifiers:\n",
        "    model.fit_algorithm(classifier=classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWTedmvNGYfB",
        "outputId": "f5a2c715-3174-4d2b-f20a-b27f1ddb8d7c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 86.0709\n",
            "max accuracy: 88.1664\n",
            "std accuracy: 0.7466\n",
            "average f1 score: 0.8580\n",
            "max f1 score: 0.8839\n",
            "std f1 score: 0.0087\n",
            "average recall: 0.8436\n",
            "max recall: 0.8709\n",
            "std recall: 0.0118\n",
            "average precision: 0.8729\n",
            "max precision: 0.8973\n",
            "std precision: 0.0113\n",
            "average time: 0.6269\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 85.7692\n",
            "max accuracy: 87.2876\n",
            "std accuracy: 0.7297\n",
            "average f1 score: 0.8530\n",
            "max f1 score: 0.8704\n",
            "std f1 score: 0.0081\n",
            "average recall: 0.8267\n",
            "max recall: 0.8513\n",
            "std recall: 0.0110\n",
            "average precision: 0.8811\n",
            "max precision: 0.9049\n",
            "std precision: 0.0108\n",
            "average time: 0.7491\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.8219\n",
            "max accuracy: 87.3462\n",
            "std accuracy: 0.7614\n",
            "average f1 score: 0.8555\n",
            "max f1 score: 0.8715\n",
            "std f1 score: 0.0080\n",
            "average recall: 0.8364\n",
            "max recall: 0.8630\n",
            "std recall: 0.0120\n",
            "average precision: 0.8755\n",
            "max precision: 0.8980\n",
            "std precision: 0.0100\n",
            "average time: 0.7232\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.3995\n",
            "max accuracy: 87.1705\n",
            "std accuracy: 0.8379\n",
            "average f1 score: 0.8530\n",
            "max f1 score: 0.8730\n",
            "std f1 score: 0.0086\n",
            "average recall: 0.8477\n",
            "max recall: 0.8733\n",
            "std recall: 0.0126\n",
            "average precision: 0.8587\n",
            "max precision: 0.8828\n",
            "std precision: 0.0112\n",
            "average time: 0.6110\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.6854\n",
            "max accuracy: 87.5220\n",
            "std accuracy: 0.6297\n",
            "average f1 score: 0.8542\n",
            "max f1 score: 0.8746\n",
            "std f1 score: 0.0073\n",
            "average recall: 0.8413\n",
            "max recall: 0.8660\n",
            "std recall: 0.0106\n",
            "average precision: 0.8677\n",
            "max precision: 0.8919\n",
            "std precision: 0.0104\n",
            "average time: 1.3260\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 85.3796\n",
            "max accuracy: 87.8149\n",
            "std accuracy: 0.7965\n",
            "average f1 score: 0.8473\n",
            "max f1 score: 0.8788\n",
            "std f1 score: 0.0093\n",
            "average recall: 0.8153\n",
            "max recall: 0.8435\n",
            "std recall: 0.0130\n",
            "average precision: 0.8820\n",
            "max precision: 0.9195\n",
            "std precision: 0.0106\n",
            "average time: 0.5358\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 85.2648\n",
            "max accuracy: 87.2291\n",
            "std accuracy: 0.8336\n",
            "average f1 score: 0.8463\n",
            "max f1 score: 0.8691\n",
            "std f1 score: 0.0090\n",
            "average recall: 0.8104\n",
            "max recall: 0.8446\n",
            "std recall: 0.0123\n",
            "average precision: 0.8857\n",
            "max precision: 0.9179\n",
            "std precision: 0.0107\n",
            "average time: 0.6841\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.1980\n",
            "max accuracy: 87.1705\n",
            "std accuracy: 0.7364\n",
            "average f1 score: 0.8471\n",
            "max f1 score: 0.8706\n",
            "std f1 score: 0.0079\n",
            "average recall: 0.8199\n",
            "max recall: 0.8455\n",
            "std recall: 0.0115\n",
            "average precision: 0.8763\n",
            "max precision: 0.8999\n",
            "std precision: 0.0111\n",
            "average time: 0.6443\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 84.3872\n",
            "max accuracy: 86.1746\n",
            "std accuracy: 0.7546\n",
            "average f1 score: 0.8425\n",
            "max f1 score: 0.8599\n",
            "std f1 score: 0.0082\n",
            "average recall: 0.8324\n",
            "max recall: 0.8607\n",
            "std recall: 0.0114\n",
            "average precision: 0.8529\n",
            "max precision: 0.8848\n",
            "std precision: 0.0113\n",
            "average time: 0.6121\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.3023\n",
            "max accuracy: 86.8776\n",
            "std accuracy: 0.7642\n",
            "average f1 score: 0.8484\n",
            "max f1 score: 0.8646\n",
            "std f1 score: 0.0081\n",
            "average recall: 0.8225\n",
            "max recall: 0.8473\n",
            "std recall: 0.0116\n",
            "average precision: 0.8760\n",
            "max precision: 0.8992\n",
            "std precision: 0.0104\n",
            "average time: 1.2679\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 85.3492\n",
            "max accuracy: 87.2876\n",
            "std accuracy: 0.7123\n",
            "average f1 score: 0.8478\n",
            "max f1 score: 0.8697\n",
            "std f1 score: 0.0082\n",
            "average recall: 0.8140\n",
            "max recall: 0.8405\n",
            "std recall: 0.0115\n",
            "average precision: 0.8846\n",
            "max precision: 0.9090\n",
            "std precision: 0.0099\n",
            "average time: 0.6203\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 85.4241\n",
            "max accuracy: 87.0533\n",
            "std accuracy: 0.7426\n",
            "average f1 score: 0.8480\n",
            "max f1 score: 0.8692\n",
            "std f1 score: 0.0084\n",
            "average recall: 0.8117\n",
            "max recall: 0.8419\n",
            "std recall: 0.0132\n",
            "average precision: 0.8880\n",
            "max precision: 0.9101\n",
            "std precision: 0.0099\n",
            "average time: 0.8195\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.4886\n",
            "max accuracy: 87.2291\n",
            "std accuracy: 0.8462\n",
            "average f1 score: 0.8495\n",
            "max f1 score: 0.8691\n",
            "std f1 score: 0.0090\n",
            "average recall: 0.8217\n",
            "max recall: 0.8508\n",
            "std recall: 0.0124\n",
            "average precision: 0.8793\n",
            "max precision: 0.9084\n",
            "std precision: 0.0113\n",
            "average time: 0.8092\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.2238\n",
            "max accuracy: 86.7604\n",
            "std accuracy: 0.7111\n",
            "average f1 score: 0.8497\n",
            "max f1 score: 0.8656\n",
            "std f1 score: 0.0076\n",
            "average recall: 0.8345\n",
            "max recall: 0.8692\n",
            "std recall: 0.0117\n",
            "average precision: 0.8657\n",
            "max precision: 0.8922\n",
            "std precision: 0.0106\n",
            "average time: 0.6902\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.1271\n",
            "max accuracy: 87.1705\n",
            "std accuracy: 0.8118\n",
            "average f1 score: 0.8452\n",
            "max f1 score: 0.8675\n",
            "std f1 score: 0.0088\n",
            "average recall: 0.8145\n",
            "max recall: 0.8415\n",
            "std recall: 0.0119\n",
            "average precision: 0.8784\n",
            "max precision: 0.9098\n",
            "std precision: 0.0102\n",
            "average time: 1.4020\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 85.9555\n",
            "max accuracy: 87.7563\n",
            "std accuracy: 0.7936\n",
            "average f1 score: 0.8567\n",
            "max f1 score: 0.8787\n",
            "std f1 score: 0.0088\n",
            "average recall: 0.8401\n",
            "max recall: 0.8653\n",
            "std recall: 0.0124\n",
            "average precision: 0.8742\n",
            "max precision: 0.8959\n",
            "std precision: 0.0102\n",
            "average time: 0.6018\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 85.7557\n",
            "max accuracy: 87.8149\n",
            "std accuracy: 0.7909\n",
            "average f1 score: 0.8531\n",
            "max f1 score: 0.8765\n",
            "std f1 score: 0.0089\n",
            "average recall: 0.8278\n",
            "max recall: 0.8578\n",
            "std recall: 0.0117\n",
            "average precision: 0.8803\n",
            "max precision: 0.9069\n",
            "std precision: 0.0119\n",
            "average time: 0.7691\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.8606\n",
            "max accuracy: 87.2291\n",
            "std accuracy: 0.6901\n",
            "average f1 score: 0.8555\n",
            "max f1 score: 0.8703\n",
            "std f1 score: 0.0074\n",
            "average recall: 0.8375\n",
            "max recall: 0.8598\n",
            "std recall: 0.0098\n",
            "average precision: 0.8744\n",
            "max precision: 0.8936\n",
            "std precision: 0.0103\n",
            "average time: 0.7524\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.2273\n",
            "max accuracy: 87.1119\n",
            "std accuracy: 0.8114\n",
            "average f1 score: 0.8519\n",
            "max f1 score: 0.8701\n",
            "std f1 score: 0.0087\n",
            "average recall: 0.8462\n",
            "max recall: 0.8778\n",
            "std recall: 0.0119\n",
            "average precision: 0.8578\n",
            "max precision: 0.8881\n",
            "std precision: 0.0126\n",
            "average time: 0.6201\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.8330\n",
            "max accuracy: 88.1664\n",
            "std accuracy: 0.7496\n",
            "average f1 score: 0.8556\n",
            "max f1 score: 0.8820\n",
            "std f1 score: 0.0084\n",
            "average recall: 0.8413\n",
            "max recall: 0.8728\n",
            "std recall: 0.0119\n",
            "average precision: 0.8706\n",
            "max precision: 0.8945\n",
            "std precision: 0.0106\n",
            "average time: 1.3447\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 86.1054\n",
            "max accuracy: 87.9906\n",
            "std accuracy: 0.6347\n",
            "average f1 score: 0.8603\n",
            "max f1 score: 0.8786\n",
            "std f1 score: 0.0067\n",
            "average recall: 0.8537\n",
            "max recall: 0.8768\n",
            "std recall: 0.0112\n",
            "average precision: 0.8671\n",
            "max precision: 0.8940\n",
            "std precision: 0.0101\n",
            "average time: 0.7470\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 85.9057\n",
            "max accuracy: 87.8735\n",
            "std accuracy: 0.8050\n",
            "average f1 score: 0.8551\n",
            "max f1 score: 0.8734\n",
            "std f1 score: 0.0088\n",
            "average recall: 0.8354\n",
            "max recall: 0.8682\n",
            "std recall: 0.0110\n",
            "average precision: 0.8759\n",
            "max precision: 0.9062\n",
            "std precision: 0.0118\n",
            "average time: 0.8133\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 86.1681\n",
            "max accuracy: 88.1664\n",
            "std accuracy: 0.7385\n",
            "average f1 score: 0.8589\n",
            "max f1 score: 0.8798\n",
            "std f1 score: 0.0082\n",
            "average recall: 0.8450\n",
            "max recall: 0.8750\n",
            "std recall: 0.0111\n",
            "average precision: 0.8734\n",
            "max precision: 0.8968\n",
            "std precision: 0.0107\n",
            "average time: 0.8213\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.5917\n",
            "max accuracy: 87.7563\n",
            "std accuracy: 0.8032\n",
            "average f1 score: 0.8555\n",
            "max f1 score: 0.8773\n",
            "std f1 score: 0.0087\n",
            "average recall: 0.8549\n",
            "max recall: 0.8840\n",
            "std recall: 0.0130\n",
            "average precision: 0.8562\n",
            "max precision: 0.8861\n",
            "std precision: 0.0113\n",
            "average time: 0.6645\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 86.1289\n",
            "max accuracy: 87.8735\n",
            "std accuracy: 0.6652\n",
            "average f1 score: 0.8603\n",
            "max f1 score: 0.8767\n",
            "std f1 score: 0.0067\n",
            "average recall: 0.8510\n",
            "max recall: 0.8720\n",
            "std recall: 0.0105\n",
            "average precision: 0.8700\n",
            "max precision: 0.8986\n",
            "std precision: 0.0092\n",
            "average time: 1.2478\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 85.3357\n",
            "max accuracy: 87.2291\n",
            "std accuracy: 0.7125\n",
            "average f1 score: 0.8472\n",
            "max f1 score: 0.8643\n",
            "std f1 score: 0.0082\n",
            "average recall: 0.8122\n",
            "max recall: 0.8392\n",
            "std recall: 0.0131\n",
            "average precision: 0.8855\n",
            "max precision: 0.9085\n",
            "std precision: 0.0091\n",
            "average time: 0.5971\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 85.2994\n",
            "max accuracy: 87.2291\n",
            "std accuracy: 0.6712\n",
            "average f1 score: 0.8472\n",
            "max f1 score: 0.8658\n",
            "std f1 score: 0.0076\n",
            "average recall: 0.8150\n",
            "max recall: 0.8374\n",
            "std recall: 0.0116\n",
            "average precision: 0.8822\n",
            "max precision: 0.9130\n",
            "std precision: 0.0087\n",
            "average time: 0.9355\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.4142\n",
            "max accuracy: 87.3462\n",
            "std accuracy: 0.8123\n",
            "average f1 score: 0.8486\n",
            "max f1 score: 0.8702\n",
            "std f1 score: 0.0087\n",
            "average recall: 0.8169\n",
            "max recall: 0.8498\n",
            "std recall: 0.0121\n",
            "average precision: 0.8830\n",
            "max precision: 0.9149\n",
            "std precision: 0.0113\n",
            "average time: 0.9364\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 83.7844\n",
            "max accuracy: 85.4716\n",
            "std accuracy: 0.8118\n",
            "average f1 score: 0.8351\n",
            "max f1 score: 0.8548\n",
            "std f1 score: 0.0091\n",
            "average recall: 0.8223\n",
            "max recall: 0.8477\n",
            "std recall: 0.0124\n",
            "average precision: 0.8485\n",
            "max precision: 0.8765\n",
            "std precision: 0.0120\n",
            "average time: 0.8183\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 52.4364\n",
            "max accuracy: 54.9502\n",
            "std accuracy: 1.2361\n",
            "average f1 score: 0.4333\n",
            "max f1 score: 0.6164\n",
            "std f1 score: 0.0681\n",
            "average recall: 0.3844\n",
            "max recall: 0.8165\n",
            "std recall: 0.1528\n",
            "average precision: 0.5414\n",
            "max precision: 0.5892\n",
            "std precision: 0.0259\n",
            "average time: 2.2625\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 86.1465\n",
            "max accuracy: 87.6977\n",
            "std accuracy: 0.6835\n",
            "average f1 score: 0.8607\n",
            "max f1 score: 0.8772\n",
            "std f1 score: 0.0073\n",
            "average recall: 0.8561\n",
            "max recall: 0.8864\n",
            "std recall: 0.0112\n",
            "average precision: 0.8655\n",
            "max precision: 0.8922\n",
            "std precision: 0.0104\n",
            "average time: 0.4356\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 86.0849\n",
            "max accuracy: 87.9906\n",
            "std accuracy: 0.7359\n",
            "average f1 score: 0.8584\n",
            "max f1 score: 0.8760\n",
            "std f1 score: 0.0076\n",
            "average recall: 0.8426\n",
            "max recall: 0.8756\n",
            "std recall: 0.0112\n",
            "average precision: 0.8749\n",
            "max precision: 0.8983\n",
            "std precision: 0.0106\n",
            "average time: 0.5380\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 86.2665\n",
            "max accuracy: 87.9320\n",
            "std accuracy: 0.6744\n",
            "average f1 score: 0.8603\n",
            "max f1 score: 0.8773\n",
            "std f1 score: 0.0073\n",
            "average recall: 0.8476\n",
            "max recall: 0.8671\n",
            "std recall: 0.0100\n",
            "average precision: 0.8736\n",
            "max precision: 0.9053\n",
            "std precision: 0.0113\n",
            "average time: 0.4175\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 84.9502\n",
            "max accuracy: 87.3462\n",
            "std accuracy: 0.7683\n",
            "average f1 score: 0.8460\n",
            "max f1 score: 0.8690\n",
            "std f1 score: 0.0089\n",
            "average recall: 0.8274\n",
            "max recall: 0.8573\n",
            "std recall: 0.0126\n",
            "average precision: 0.8655\n",
            "max precision: 0.8932\n",
            "std precision: 0.0125\n",
            "average time: 0.4473\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 86.2847\n",
            "max accuracy: 88.3421\n",
            "std accuracy: 0.7341\n",
            "average f1 score: 0.8622\n",
            "max f1 score: 0.8820\n",
            "std f1 score: 0.0076\n",
            "average recall: 0.8566\n",
            "max recall: 0.8856\n",
            "std recall: 0.0108\n",
            "average precision: 0.8680\n",
            "max precision: 0.8930\n",
            "std precision: 0.0109\n",
            "average time: 0.9739\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: XGBClassifier\n",
            "number of iterations: 100\n",
            "average accuracy: 86.1834\n",
            "max accuracy: 87.6977\n",
            "std accuracy: 0.7964\n",
            "average f1 score: 0.8610\n",
            "max f1 score: 0.8809\n",
            "std f1 score: 0.0079\n",
            "average recall: 0.8555\n",
            "max recall: 0.8888\n",
            "std recall: 0.0120\n",
            "average precision: 0.8666\n",
            "max precision: 0.8884\n",
            "std precision: 0.0096\n",
            "average time: 0.4916\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=2),\n",
            "                   learning_rate=0.05, n_estimators=100, random_state=42)\n",
            "number of iterations: 100\n",
            "average accuracy: 86.0861\n",
            "max accuracy: 88.1078\n",
            "std accuracy: 0.7094\n",
            "average f1 score: 0.8584\n",
            "max f1 score: 0.8806\n",
            "std f1 score: 0.0078\n",
            "average recall: 0.8432\n",
            "max recall: 0.8806\n",
            "std recall: 0.0109\n",
            "average precision: 0.8744\n",
            "max precision: 0.8971\n",
            "std precision: 0.0106\n",
            "average time: 0.5397\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: GradientBoostingClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 86.1845\n",
            "max accuracy: 87.9320\n",
            "std accuracy: 0.7438\n",
            "average f1 score: 0.8607\n",
            "max f1 score: 0.8784\n",
            "std f1 score: 0.0079\n",
            "average recall: 0.8535\n",
            "max recall: 0.8824\n",
            "std recall: 0.0119\n",
            "average precision: 0.8683\n",
            "max precision: 0.8975\n",
            "std precision: 0.0103\n",
            "average time: 0.4047\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: RandomForestClassifier()\n",
            "number of iterations: 100\n",
            "average accuracy: 85.3263\n",
            "max accuracy: 87.3462\n",
            "std accuracy: 0.8831\n",
            "average f1 score: 0.8499\n",
            "max f1 score: 0.8700\n",
            "std f1 score: 0.0097\n",
            "average recall: 0.8290\n",
            "max recall: 0.8659\n",
            "std recall: 0.0131\n",
            "average precision: 0.8722\n",
            "max precision: 0.9081\n",
            "std precision: 0.0125\n",
            "average time: 0.4276\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: SVC()\n",
            "number of iterations: 100\n",
            "average accuracy: 86.3228\n",
            "max accuracy: 88.2250\n",
            "std accuracy: 0.8079\n",
            "average f1 score: 0.8620\n",
            "max f1 score: 0.8828\n",
            "std f1 score: 0.0088\n",
            "average recall: 0.8547\n",
            "max recall: 0.8820\n",
            "std recall: 0.0121\n",
            "average precision: 0.8695\n",
            "max precision: 0.8938\n",
            "std precision: 0.0115\n",
            "average time: 0.9331\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in models:\n",
        "  model.fit_algorithm(classifier=model.ensemble_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UPC5USOOsv9",
        "outputId": "47c04fe1-364f-4a4f-d145-06ef640ae1f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 85.9754\n",
            "max accuracy: 87.4048\n",
            "std accuracy: 0.7626\n",
            "average f1 score: 0.8559\n",
            "max f1 score: 0.8708\n",
            "std f1 score: 0.0080\n",
            "average recall: 0.8379\n",
            "max recall: 0.8677\n",
            "std recall: 0.0100\n",
            "average precision: 0.8748\n",
            "max precision: 0.8952\n",
            "std precision: 0.0103\n",
            "average time: 8.6753\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 85.3193\n",
            "max accuracy: 87.4048\n",
            "std accuracy: 0.7641\n",
            "average f1 score: 0.8482\n",
            "max f1 score: 0.8718\n",
            "std f1 score: 0.0084\n",
            "average recall: 0.8169\n",
            "max recall: 0.8359\n",
            "std recall: 0.0116\n",
            "average precision: 0.8821\n",
            "max precision: 0.9126\n",
            "std precision: 0.0099\n",
            "average time: 8.2377\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 85.5770\n",
            "max accuracy: 87.1119\n",
            "std accuracy: 0.6296\n",
            "average f1 score: 0.8494\n",
            "max f1 score: 0.8698\n",
            "std f1 score: 0.0075\n",
            "average recall: 0.8176\n",
            "max recall: 0.8390\n",
            "std recall: 0.0103\n",
            "average precision: 0.8838\n",
            "max precision: 0.9087\n",
            "std precision: 0.0110\n",
            "average time: 9.3642\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 86.0203\n",
            "max accuracy: 87.1705\n",
            "std accuracy: 0.5650\n",
            "average f1 score: 0.8567\n",
            "max f1 score: 0.8675\n",
            "std f1 score: 0.0068\n",
            "average recall: 0.8364\n",
            "max recall: 0.8523\n",
            "std recall: 0.0092\n",
            "average precision: 0.8781\n",
            "max precision: 0.9073\n",
            "std precision: 0.0121\n",
            "average time: 8.7806\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 86.0847\n",
            "max accuracy: 87.3462\n",
            "std accuracy: 0.5785\n",
            "average f1 score: 0.8586\n",
            "max f1 score: 0.8729\n",
            "std f1 score: 0.0075\n",
            "average recall: 0.8468\n",
            "max recall: 0.8740\n",
            "std recall: 0.0108\n",
            "average precision: 0.8708\n",
            "max precision: 0.8890\n",
            "std precision: 0.0086\n",
            "average time: 8.5478\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 85.2392\n",
            "max accuracy: 87.0533\n",
            "std accuracy: 0.7018\n",
            "average f1 score: 0.8458\n",
            "max f1 score: 0.8661\n",
            "std f1 score: 0.0083\n",
            "average recall: 0.8122\n",
            "max recall: 0.8355\n",
            "std recall: 0.0119\n",
            "average precision: 0.8824\n",
            "max precision: 0.9039\n",
            "std precision: 0.0112\n",
            "average time: 13.7843\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 86.1043\n",
            "max accuracy: 88.4007\n",
            "std accuracy: 0.6811\n",
            "average f1 score: 0.8599\n",
            "max f1 score: 0.8835\n",
            "std f1 score: 0.0072\n",
            "average recall: 0.8499\n",
            "max recall: 0.8722\n",
            "std recall: 0.0092\n",
            "average precision: 0.8702\n",
            "max precision: 0.8951\n",
            "std precision: 0.0107\n",
            "average time: 6.5739\n",
            "\n",
            "\n",
            "\n",
            "algorithm name: EnsembleModel\n",
            "number of iterations: 30\n",
            "average accuracy: 86.4245\n",
            "max accuracy: 87.7563\n",
            "std accuracy: 0.7610\n",
            "average f1 score: 0.8641\n",
            "max f1 score: 0.8764\n",
            "std f1 score: 0.0076\n",
            "average recall: 0.8581\n",
            "max recall: 0.8781\n",
            "std recall: 0.0105\n",
            "average precision: 0.8704\n",
            "max precision: 0.8952\n",
            "std precision: 0.0119\n",
            "average time: 6.5752\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}